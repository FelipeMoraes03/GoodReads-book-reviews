{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/goodreads.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando as isntâncias úteis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coluna `is_read` presente no dataset é uma coluna que indica se o livro foi ou não lido pelo usuário, portanto instâncias na qual o valor dessa coluna é 'false' serão inúteis, visto que se um usuário não leu um livro ele não terá avaliado o mesmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_read'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando apenas as instâncias correspondentes a usuários que leram o livro respectivo\n",
    "df = df[df['is_read'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de linhas: 2008206\n"
     ]
    }
   ],
   "source": [
    "# Verificando quantas instâncias ainda estão presentes no dataframe\n",
    "print(f\"Total de linhas: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando valores duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o objetivo futuro será criar um modelo para prever a avaliação de um usuário para um determinado livro, precisamos verificar se existe alguma linha com a combinação de `user_id` e `book_id` duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated(subset=['user_id', 'book_id']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não há nenhuma instância duplicada, por isso não é necessário nenhum tratamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo o dataset em Treino, Validação e Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de realizar o tratamento de valores ausentes em um dataset, é fundamental dividir os conjuntos de treino, validação e teste. Isso é importante porque tratar valores ausentes antes da divisão pode introduzir vazamento de dados, o que ocorre quando informações do conjunto de teste influenciam os dados de treino, resultando em uma avaliação enviesada do modelo que será treinado no futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df : pd.DataFrame, train_frac: float = 0.5, val_frac: float = 0.25, \n",
    "               test_frac: float = 0.25) -> list[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Split a DataFrame into training, validation, and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    df: The DataFrame to be split.\n",
    "    train_frac: The fraction of the data to include in the training set.\n",
    "    val_frac: The fraction of the data to include in the validation set.\n",
    "    test_frac: The fraction of the data to include in the test set.\n",
    "\n",
    "    Returns:\n",
    "    A list containing three DataFrames: the training set, the validation set, and the test set.\n",
    "    \"\"\"\n",
    "\n",
    "    assert train_frac + val_frac + test_frac == 1\n",
    "\n",
    "    df = df.sample(frac=1, replace=False).reset_index(drop=True)\n",
    "\n",
    "    qtd_lines = df.shape[0]\n",
    "\n",
    "    train = df.iloc[:int(qtd_lines * train_frac)]\n",
    "    validation = df.iloc[int(qtd_lines * train_frac) : int(qtd_lines * (1-test_frac))]\n",
    "    test = df.iloc[int(qtd_lines * (1-test_frac)):]\n",
    "\n",
    "    return train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = split_data(df, train_frac=0.6, val_frac=0.2, test_frac=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_text_reviews_count         1\n",
      "language_code              574227\n",
      "is_ebook                        1\n",
      "book_rating                     1\n",
      "book_format                252175\n",
      "author_id                       5\n",
      "num_pages                  208777\n",
      "publication_year           234113\n",
      "book_ratings_count              1\n",
      "book_genre                  33287\n",
      "author_rating                   5\n",
      "author_reviews_count            5\n",
      "author_ratings_count            5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificando quais colunas possuem valores nulos\n",
    "nan_columns = df_train.isnull().sum()\n",
    "nan_columns = nan_columns[nan_columns > 0]\n",
    "\n",
    "print(nan_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando as colunas que possuem valores nulos é perceptível que as colunas `language_code`, `book_format`, `num_pages`, `publication_year` e `book_genre` possuem uma grande quantidade de valores nulos, por isso devem ser tratadas de forma diferente das demais colunas.\n",
    "\n",
    "Para tratar as colunas com valores numéricos (`num_pages` e `publication_year`) é possível utilizar a média de todos os valores **do conjunto de treino** (para evitar vazamento de dados) dessa coluna, no entanto para as colunas com valores categóricos é necessário fazer o tratamento de forma diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituindo os valores nulos das colunas numéricas pela média dos demais valores\n",
    "df_train['num_pages'] = df_train['num_pages'].fillna(df_train['num_pages'].mean()).astype('int64')\n",
    "df_val['num_pages'] = df_val['num_pages'].fillna(df_train['num_pages'].mean()).astype('int64')\n",
    "df_test['num_pages'] = df_test['num_pages'].fillna(df_train['num_pages'].mean()).astype('int64')\n",
    "\n",
    "df_train['publication_year'] = df_train['publication_year'].fillna(df_train['publication_year'].mean()).astype('int64')\n",
    "df_val['publication_year'] = df_val['publication_year'].fillna(df_train['publication_year'].mean()).astype('int64')\n",
    "df_test['publication_year'] = df_test['publication_year'].fillna(df_train['publication_year'].mean()).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language_code: 56\n",
      "book_format: 113\n",
      "book_genre: 11\n"
     ]
    }
   ],
   "source": [
    "# Verificando a quantidade de valores distintos nas colunas categóricas\n",
    "print(f\"language_code: {df_train['language_code'].nunique(dropna=False)}\")\n",
    "print(f\"book_format: {df_train['book_format'].nunique(dropna=False)}\")\n",
    "print(f\"book_genre: {df_train['book_genre'].nunique(dropna=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a quantidade de valores distintos em cada coluna é muito grande, e será necessário fazer um tratamento a respeito disso no futuro, vamos criar um novo valor para cada coluna referente a \"outros\", no qual vamos colocar os valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando e imprimindo as linhas que possuem valores NaN em qualquer coluna\n",
    "rows_with_nan = df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['language_code'] = df_train['language_code'].fillna('other')\n",
    "df_train['book_format'] = df_train['book_format'].fillna('other')\n",
    "df_train['book_genre'] = df_train['book_genre'].fillna('other')\n",
    "\n",
    "df_val['language_code'] = df_val['language_code'].fillna('other')\n",
    "df_val['book_format'] = df_val['book_format'].fillna('other')\n",
    "df_val['book_genre'] = df_val['book_genre'].fillna('other')\n",
    "\n",
    "df_test['language_code'] = df_test['language_code'].fillna('other')\n",
    "df_test['book_format'] = df_test['book_format'].fillna('other')\n",
    "df_test['book_genre'] = df_test['book_genre'].fillna('other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que os valores nulos das linhas mais significativas foram tratados, vamos tratar os demais valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_text_reviews_count</th>\n",
       "      <th>language_code</th>\n",
       "      <th>is_ebook</th>\n",
       "      <th>book_rating</th>\n",
       "      <th>book_format</th>\n",
       "      <th>author_id</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>book_id</th>\n",
       "      <th>book_ratings_count</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_genre</th>\n",
       "      <th>author_rating</th>\n",
       "      <th>author_reviews_count</th>\n",
       "      <th>author_ratings_count</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_read</th>\n",
       "      <th>rating</th>\n",
       "      <th>is_reviewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47328</th>\n",
       "      <td>2.0</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>2.91</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301</td>\n",
       "      <td>1999</td>\n",
       "      <td>711979</td>\n",
       "      <td>11.0</td>\n",
       "      <td>تهران شهر بی آسمان</td>\n",
       "      <td>fiction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47989</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495929</th>\n",
       "      <td>2.0</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>2.91</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301</td>\n",
       "      <td>1999</td>\n",
       "      <td>711979</td>\n",
       "      <td>11.0</td>\n",
       "      <td>تهران شهر بی آسمان</td>\n",
       "      <td>fiction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46763</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537966</th>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301</td>\n",
       "      <td>1999</td>\n",
       "      <td>1473309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>دشمن عزیز</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52456</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723513</th>\n",
       "      <td>2.0</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>2.91</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301</td>\n",
       "      <td>1999</td>\n",
       "      <td>711979</td>\n",
       "      <td>11.0</td>\n",
       "      <td>تهران شهر بی آسمان</td>\n",
       "      <td>fiction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16890</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007264</th>\n",
       "      <td>2.0</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "      <td>2.91</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301</td>\n",
       "      <td>1999</td>\n",
       "      <td>711979</td>\n",
       "      <td>11.0</td>\n",
       "      <td>تهران شهر بی آسمان</td>\n",
       "      <td>fiction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8869</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         book_text_reviews_count language_code is_ebook  book_rating  \\\n",
       "47328                        2.0         other    False         2.91   \n",
       "495929                       2.0         other    False         2.91   \n",
       "537966                       NaN         other      NaN          NaN   \n",
       "723513                       2.0         other    False         2.91   \n",
       "1007264                      2.0         other    False         2.91   \n",
       "\n",
       "        book_format  author_id  num_pages  publication_year  book_id  \\\n",
       "47328         other        NaN        301              1999   711979   \n",
       "495929        other        NaN        301              1999   711979   \n",
       "537966        other        NaN        301              1999  1473309   \n",
       "723513        other        NaN        301              1999   711979   \n",
       "1007264       other        NaN        301              1999   711979   \n",
       "\n",
       "         book_ratings_count          book_title book_genre  author_rating  \\\n",
       "47328                  11.0  تهران شهر بی آسمان    fiction            NaN   \n",
       "495929                 11.0  تهران شهر بی آسمان    fiction            NaN   \n",
       "537966                  NaN           دشمن عزیز      other            NaN   \n",
       "723513                 11.0  تهران شهر بی آسمان    fiction            NaN   \n",
       "1007264                11.0  تهران شهر بی آسمان    fiction            NaN   \n",
       "\n",
       "         author_reviews_count  author_ratings_count  user_id  is_read  rating  \\\n",
       "47328                     NaN                   NaN    47989        1       4   \n",
       "495929                    NaN                   NaN    46763        1       5   \n",
       "537966                    NaN                   NaN    52456        1       0   \n",
       "723513                    NaN                   NaN    16890        1       2   \n",
       "1007264                   NaN                   NaN     8869        1       3   \n",
       "\n",
       "         is_reviewed  \n",
       "47328              1  \n",
       "495929             0  \n",
       "537966             1  \n",
       "723513             1  \n",
       "1007264            0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando todas as linhas que ainda possuem valores nulos\n",
    "df_train[df_train.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pode-se perceber que apenas 2 livros distintos são responsáveis por todas essas instâncias com valores nulos, portanto podemos remover elas sem grandes prejuízos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Verificando quais colunas possuem valores nulos\n",
    "nan_columns = df_train.isnull().sum()\n",
    "nan_columns = nan_columns[nan_columns > 0]\n",
    "\n",
    "print(nan_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando os conjuntos de Treino, Validação e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('clean_data/train.csv', index=False, sep=';', encoding='utf-8', header=True)\n",
    "df_val.to_csv('clean_data/val.csv', index=False, sep=';', encoding='utf-8', header=True)\n",
    "df_test.to_csv('clean_data/test.csv', index=False, sep=';', encoding='utf-8', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goodreads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
