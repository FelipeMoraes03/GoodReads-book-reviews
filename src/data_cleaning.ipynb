{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw_data/goodreads.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando valores duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o objetivo futuro será criar um modelo para prever a média das avaliações de usuários para um determinado livro, precisamos verificar se existe alguma linha com valores de `book_id` duplicados, visto que dois livros iguais com dados diferentes seria um problema para etapas futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated(subset=['book_id']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não há nenhuma instância duplicada, por isso não é necessário nenhum tratamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo o dataset em Treino, Validação e Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de realizar o tratamento de valores ausentes em um dataset, é fundamental dividir os conjuntos de treino, validação e teste. Isso é importante porque tratar valores ausentes antes da divisão pode introduzir vazamento de dados, o que ocorre quando informações do conjunto de teste influenciam os dados de treino, resultando em uma avaliação enviesada do modelo que será treinado no futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df : pd.DataFrame, train_frac: float = 0.5, val_frac: float = 0.25, \n",
    "               test_frac: float = 0.25) -> list[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Split a DataFrame into training, validation, and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    df: The DataFrame to be split.\n",
    "    train_frac: The fraction of the data to include in the training set.\n",
    "    val_frac: The fraction of the data to include in the validation set.\n",
    "    test_frac: The fraction of the data to include in the test set.\n",
    "\n",
    "    Returns:\n",
    "    A list containing three DataFrames: the training set, the validation set, and the test set.\n",
    "    \"\"\"\n",
    "\n",
    "    assert train_frac + val_frac + test_frac == 1\n",
    "\n",
    "    df = df.sample(frac=1, replace=False).reset_index(drop=True)\n",
    "\n",
    "    qtd_lines = df.shape[0]\n",
    "\n",
    "    train = df.iloc[:int(qtd_lines * train_frac)]\n",
    "    validation = df.iloc[int(qtd_lines * train_frac) : int(qtd_lines * (1-test_frac))]\n",
    "    test = df.iloc[int(qtd_lines * (1-test_frac)):]\n",
    "\n",
    "    return train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = split_data(df, train_frac=0.6, val_frac=0.2, test_frac=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language_code       21685\n",
      "book_format         18152\n",
      "num_pages           16109\n",
      "publication_year    15857\n",
      "book_genre            561\n",
      "author_name             1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificando quais colunas possuem valores nulos\n",
    "nan_columns = df_train.isnull().sum()\n",
    "nan_columns = nan_columns[nan_columns > 0]\n",
    "\n",
    "print(nan_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando as colunas que possuem valores nulos é perceptível que as colunas `language_code`, `book_format`, `num_pages`, `publication_year` e `book_genre` possuem uma grande quantidade de valores nulos, por isso devem ser tratadas de forma diferente das demais colunas.\n",
    "\n",
    "Para tratar as colunas com valores numéricos (`num_pages` e `publication_year`) é possível utilizar a média de todos os valores **do conjunto de treino** (para evitar vazamento de dados) dessa coluna, no entanto para as colunas com valores categóricos é necessário fazer o tratamento de forma diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituindo os valores nulos das colunas numéricas pela média dos demais valores\n",
    "df_train['num_pages'] = df_train['num_pages'].fillna(df_train['num_pages'].mean()).astype('int64')\n",
    "df_val['num_pages'] = df_val['num_pages'].fillna(df_train['num_pages'].mean()).astype('int64')\n",
    "df_test['num_pages'] = df_test['num_pages'].fillna(df_train['num_pages'].mean()).astype('int64')\n",
    "\n",
    "df_train['publication_year'] = df_train['publication_year'].fillna(df_train['publication_year'].mean()).astype('int64')\n",
    "df_val['publication_year'] = df_val['publication_year'].fillna(df_train['publication_year'].mean()).astype('int64')\n",
    "df_test['publication_year'] = df_test['publication_year'].fillna(df_train['publication_year'].mean()).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language_code: 76\n",
      "book_format: 131\n",
      "book_genre: 11\n"
     ]
    }
   ],
   "source": [
    "# Verificando a quantidade de valores distintos nas colunas categóricas\n",
    "print(f\"language_code: {df_train['language_code'].nunique(dropna=False)}\")\n",
    "print(f\"book_format: {df_train['book_format'].nunique(dropna=False)}\")\n",
    "print(f\"book_genre: {df_train['book_genre'].nunique(dropna=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a quantidade de valores distintos em cada coluna é muito grande, e será necessário fazer um tratamento a respeito disso no futuro, vamos criar um novo valor para cada coluna referente a \"outros\", no qual vamos colocar os valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando e imprimindo as linhas que possuem valores NaN em qualquer coluna\n",
    "rows_with_nan = df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['language_code'] = df_train['language_code'].fillna('other')\n",
    "df_train['book_format'] = df_train['book_format'].fillna('other')\n",
    "df_train['book_genre'] = df_train['book_genre'].fillna('other')\n",
    "\n",
    "df_val['language_code'] = df_val['language_code'].fillna('other')\n",
    "df_val['book_format'] = df_val['book_format'].fillna('other')\n",
    "df_val['book_genre'] = df_val['book_genre'].fillna('other')\n",
    "\n",
    "df_test['language_code'] = df_test['language_code'].fillna('other')\n",
    "df_test['book_format'] = df_test['book_format'].fillna('other')\n",
    "df_test['book_genre'] = df_test['book_genre'].fillna('other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que os valores nulos das linhas mais significativas foram tratados, vamos tratar os demais valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_text_reviews_count</th>\n",
       "      <th>language_code</th>\n",
       "      <th>is_ebook</th>\n",
       "      <th>book_rating</th>\n",
       "      <th>book_format</th>\n",
       "      <th>author_id</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>book_id</th>\n",
       "      <th>book_ratings_count</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_genre</th>\n",
       "      <th>author_rating</th>\n",
       "      <th>author_reviews_count</th>\n",
       "      <th>author_name</th>\n",
       "      <th>author_ratings_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56507</th>\n",
       "      <td>33</td>\n",
       "      <td>ara</td>\n",
       "      <td>False</td>\n",
       "      <td>4.18</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>6421865</td>\n",
       "      <td>190</td>\n",
       "      <td>2013</td>\n",
       "      <td>18721152</td>\n",
       "      <td>178</td>\n",
       "      <td>أوناس</td>\n",
       "      <td>other</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       book_text_reviews_count language_code  is_ebook  book_rating  \\\n",
       "56507                       33           ara     False         4.18   \n",
       "\n",
       "      book_format  author_id  num_pages  publication_year   book_id  \\\n",
       "56507   Paperback    6421865        190              2013  18721152   \n",
       "\n",
       "       book_ratings_count book_title book_genre  author_rating  \\\n",
       "56507                 178      أوناس      other            4.0   \n",
       "\n",
       "       author_reviews_count author_name  author_ratings_count  \n",
       "56507                    70         NaN                   388  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando todas as linhas que ainda possuem valores nulos\n",
    "df_train[df_train.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pode-se perceber que na maioria das instâncias nas quais existem valores nulos, esse valores também se encontram na variável alvo `book_rating`. Visto que sem essa variável não é possível treinar nem avaliar o modelo, vamos remover todas as instâncias com valores ausentes nessa coluna.\n",
    "\n",
    "Além disso, nota-se que grande parte dessas instâncias não possuem dados em nenhuma coluna, logo não são capazes de trazer nenhum valor para o dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna(subset=['book_rating'])\n",
    "df_val = df_val.dropna(subset=['book_rating'])\n",
    "df_test = df_test.dropna(subset=['book_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author_name    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificando quais colunas possuem valores nulos\n",
    "nan_columns = df_train.isnull().sum()\n",
    "nan_columns = nan_columns[nan_columns > 0]\n",
    "\n",
    "print(nan_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainda há uma instância com valor ausente na coluna de `author_name`, entretanto como o nome do autor é uma variável que será descartada futuramente para a criação do modelo, pode-se ignorar esse valor nausente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando os conjuntos de Treino, Validação e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('../data/clean_data/train.csv', index=False, sep=';', encoding='utf-8', header=True)\n",
    "df_val.to_csv('../data/clean_data/val.csv', index=False, sep=';', encoding='utf-8', header=True)\n",
    "df_test.to_csv('../data/clean_data/test.csv', index=False, sep=';', encoding='utf-8', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goodreads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
